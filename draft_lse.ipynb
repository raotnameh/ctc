{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from time import time\n",
    "import json, pickle, os, string, kenlm, json\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby\n",
    "import Levenshtein as Lev\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(*args):\n",
    "    \"\"\"\n",
    "    Stable log sum exp.\n",
    "    \"\"\"\n",
    "    if all(a == -float('inf') for a in args):\n",
    "        return -float('inf')\n",
    "    a_max = max(args)\n",
    "#     print('--',args)\n",
    "#     args = [i for i in args] + [-float('inf')]\n",
    "    lsp = math.log(sum(math.exp(a - a_max)\n",
    "                      for a in args))\n",
    "    return a_max + lsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_(s1, s2):\n",
    "    b = set(s1.split() + s2.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    \n",
    "    return Lev.distance(''.join(w1), ''.join(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load(\"out.npy\")[0]\n",
    "with open(\"true.txt\", \"r\") as f:\n",
    "    reference = f.read()\n",
    "with open(\"pred.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_best_path(out,labels):\n",
    "    \"implements best path decoding as shown by Graves\"\n",
    "    out = [labels[i] for i in np.argmax(out, axis=1) if i!=labels[-1]]\n",
    "    o = \"\"\n",
    "    for i,j in groupby(out):\n",
    "        o = o + i\n",
    "    return o.replace(\"_\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND CHARGED IFEVER HE MIGHT FIND SIR GAWANE AND SIR UWANE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAY DHAS OR MORE HOUSE TO RIDE WITH THEM TO THE KING'S COURT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.076923076923077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gred_txt = ctc_best_path(out,labels)\n",
    "print(gred_txt)\n",
    "wer_(gred_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beam search decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_w = kenlm.LanguageModel('/home/hemant/4_gram.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_bsp(out,labels, prune=0.00001, beam_size=25,alpha=1.45,beta=3,lm=None):\n",
    "    \n",
    "    blank_symbol = '_'\n",
    "    F = out.shape[1] # length of labels\n",
    "    steps = out.shape[0] # number of time steps\n",
    "    \n",
    "    t_b = [('', (1.0 ,0.0 ))] # beam at every time step gets updated\n",
    "    t_1 = None\n",
    "    \n",
    "    for t in tqdm(range(0,steps)):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t]>prune)[0]]\n",
    "        dummy_beam = defaultdict(lambda: (0,0))\n",
    "        dummy = t_b\n",
    "        for prefix, (pb,pnb) in t_b:\n",
    "            for c in pruned_alphabet:\n",
    "                p_t = out[t][labels.index(c)]\n",
    "                \n",
    "                if c == blank_symbol:\n",
    "                    dpb,dpnb = dummy_beam[prefix]\n",
    "                    dpb += p_t*(pb + pnb)\n",
    "                    dummy_beam[prefix] = (dpb,dpnb)\n",
    "                    continue\n",
    "                \n",
    "                end_t = prefix[-1] if prefix else None\n",
    "                c_t = prefix + c\n",
    "                dpb,dpnb = dummy_beam[c_t]\n",
    "                if c == end_t and len(prefix) > 0:\n",
    "                    dpb_,dpnb_ = dummy_beam[prefix]\n",
    "                    dpnb += p_t*pb\n",
    "                    dpnb_ += p_t*pnb\n",
    "                    dummy_beam[prefix] = (dpb_,dpnb_)\n",
    "                    \n",
    "                elif c == ' ' and len(prefix.strip().split(' ')) > 1:\n",
    "                    if prefix.upper().split()[-1] in lm:\n",
    "                        prob = ([10**i[0] for i in lm.full_scores(c_t.upper(),eos=False,bos=False)][-1])**alpha\n",
    "                    else: \n",
    "                        prob = 0.00000001\n",
    "                        \n",
    "                    word_inser = (len(prefix.strip().split(' ')))**beta\n",
    "                    dpnb += prob*p_t*(pb + pnb)*word_inser\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    dpnb += p_t*(pb + pnb)\n",
    "                dummy_beam[c_t] = (dpb,dpnb)\n",
    "\n",
    "                if c_t not in t_b and t_1 != None:\n",
    "                    dpbn,dpnbn = dummy_beam[c_t]\n",
    "                    for i in t_1:\n",
    "                        if i[0] == c_t:\n",
    "                            b_, nb_  = i[1][0], i[1][1]\n",
    "                        else:\n",
    "                            b_, nb_  = 0, 0\n",
    "                    dpbn  += out[t][labels.index(\"_\")]*(b_ + nb_)\n",
    "                    dpnbn += p_t*nb_\n",
    "                    dummy_beam[c_t] = (dpbn,dpnbn)\n",
    "\n",
    "        t_1 = t_b\n",
    "        t_b = sorted(dummy_beam.items(),\n",
    "                      key=lambda x:np.sum(x[1]),\n",
    "                      reverse=True)\n",
    "        t_b = t_b[:beam_size]\n",
    "        \n",
    "    \n",
    "    best = sorted([(10**lm.score(i[0],bos=True, eos=False),i[0]) for i in t_b],reverse=True)[0][1]\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262fd86b9c874e1d8ae09866d4500244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=681.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR ORHOUSE TO RIDE WITH THEM TO THE KING'S COURT \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.564102564102564"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prune=0.00001, beam_size=75,alpha=1.45,beta=3,lm=lm_w\n",
    "beam_txt = prefix_bsp(out,labels,prune=0.00001, beam_size=500,alpha=1.6,beta=3,lm=lm_w)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.strip().split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR MARHAUS TO RIDE WITH THEM TO THE KING'S COURT\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_bsl(out,labels, prune=0.00001, beam_size=20,alpha=0.01,beta=0,lm=None):\n",
    "    \n",
    "    blank_symbol = '_'\n",
    "    F = out.shape[1] # length of labels\n",
    "    steps = out.shape[0] # number of time steps\n",
    "    prob_ = out\n",
    "    out = np.log(out)\n",
    "    NEG_INF = -float(\"inf\")\n",
    "    \n",
    "    t_b = [('', (0.0, NEG_INF ))] # beam at every time step gets updated\n",
    "    t_1 = None\n",
    "    \n",
    "    for t in tqdm(range(0,steps)):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(prob_[t]>prune)[0]]\n",
    "        dummy_beam = defaultdict(lambda: (NEG_INF, NEG_INF))\n",
    "        dummy = t_b\n",
    "        for prefix, (pb,pnb) in t_b:\n",
    "            for c in pruned_alphabet:\n",
    "                p_t = out[t][labels.index(c)]\n",
    "                \n",
    "                if c == blank_symbol:\n",
    "                    dpb,dpnb = dummy_beam[prefix]\n",
    "                    dpb = lse(dpb, p_t+pb, p_t+pnb)\n",
    "                    dummy_beam[prefix] = (dpb,dpnb)\n",
    "                    continue\n",
    "                \n",
    "                end_t = prefix[-1] if prefix else None\n",
    "                c_t = prefix + c\n",
    "                dpb,dpnb = dummy_beam[c_t]\n",
    "                if c == end_t and len(prefix) > 0:\n",
    "                    dpb_,dpnb_ = dummy_beam[prefix]\n",
    "                    dpnb = lse(dpnb,p_t+pb)\n",
    "                    dpnb_ = lse(dpnb_,p_t+pnb)\n",
    "                    dummy_beam[prefix] = (dpb_,dpnb_)\n",
    "                    \n",
    "                elif c == ' ' and len(prefix.strip().split(' ')) > 1:\n",
    "                    if prefix.upper().split()[-1] in lm:\n",
    "                        prob = 10**[i for i in lm.full_scores(c_t.upper(),eos=False,bos=False)][-1][0]\n",
    "                        prob = alpha*math.log(prob)\n",
    "                    else: \n",
    "                        prob = -1000\n",
    "                    word_inser = beta*math.log((len(prefix.strip().split(' '))))\n",
    "#                     print(prefix, '--' ,prob,word_inser,lse(dpnb,p_t+pb, p_t+pnb),lse(dpnb,p_t+pb, p_t+pnb,prob+word_inser))\n",
    "                    \n",
    "                    dpnb = lse(dpnb,p_t+pb, p_t+pnb) + prob+word_inser\n",
    "                \n",
    "                else:\n",
    "                    dpnb = lse(dpnb, p_t+pb, p_t+ pnb)\n",
    "                dummy_beam[c_t] = (dpb,dpnb)\n",
    "                \n",
    "                if c_t not in t_b and t_1 != None:\n",
    "                    dpbn,dpnbn = dummy_beam[c_t]\n",
    "                    for i in t_1:\n",
    "                        if i[0] == c_t:\n",
    "                            b_, nb_  = i[1][0], i[1][1]\n",
    "                        else:\n",
    "                            b_, nb_  = NEG_INF, NEG_INF\n",
    "                    dpbn  = lse(dpbn,out[t][labels.index(\"_\")]+b_, out[t][labels.index(\"_\")]+ nb_)\n",
    "                    dpnbn = lse(dpnbn, p_t+nb_)\n",
    "                    dummy_beam[c_t] = (dpbn,dpnbn)\n",
    "\n",
    "        t_1 = t_b\n",
    "        t_b = sorted(dummy_beam.items(),\n",
    "                      key=lambda x:lse(*x[1]),\n",
    "                      reverse=True)\n",
    "        t_b = t_b[:beam_size]\n",
    "        \n",
    "\n",
    "    best = sorted([(10**lm.score(i[0],bos=True, eos=False),i[0]) for i in t_b],reverse=True)[0][1]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0fe9fae8da470dac072f6a22cf66bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=681.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beam_txt = prefix_bsl(out,labels,prune=0.00, beam_size=50,alpha=1.4,beta=6,lm=lm_w)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.strip().split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR MARHAUS TO RIDE WITH THEM TO THE KING'S COURT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05182333219773941"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4*(math.log(10**[i for i in lm_w.full_scores('and charged if ever'.upper(),eos=False,bos=False)][-1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
