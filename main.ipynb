{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import kenlm, json, os, math\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "import Levenshtein as Lev\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(*args):\n",
    "    \"\"\"\n",
    "    Stable log sum exp.\n",
    "    \"\"\"\n",
    "    if all(a == -float('inf') for a in args):\n",
    "        return -float('inf')\n",
    "    a_max = max(args)\n",
    "    lsp = math.log(sum(math.exp(a - a_max)\n",
    "                      for a in args))\n",
    "    return a_max + lsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_(s1, s2):\n",
    "    b = set(s1.split() + s2.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    \n",
    "    return Lev.distance(''.join(w1), ''.join(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load(\"out.npy\")[0]\n",
    "with open(\"true.txt\", \"r\") as f:\n",
    "    reference = f.read()\n",
    "with open(\"pred.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# greedy decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_best_path(out,labels):\n",
    "    \"implements best path decoding as shown by Graves\"\n",
    "    out = [labels[i] for i in np.argmax(out, axis=1) if i!=labels[-1]]\n",
    "    o = \"\"\n",
    "    for i,j in groupby(out):\n",
    "        o = o + i\n",
    "    return o.replace(\"_\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND CHARGED IFEVER HE MIGHT FIND SIR GAWANE AND SIR UWANE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAY DHAS OR MORE HOUSE TO RIDE WITH THEM TO THE KING'S COURT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.076923076923077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gred_txt = ctc_best_path(out,labels)\n",
    "print(gred_txt)\n",
    "wer_(gred_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer(object):\n",
    "\n",
    "    def __init__(self, alpha, beta, model_path,oov_weight=1):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.oov_weight = oov_weight\n",
    "        if not os.path.isfile(model_path):\n",
    "            raise IOError(\"Invaid language model path: %s\" % model_path)\n",
    "        self.lm = kenlm.LanguageModel(model_path)\n",
    "\n",
    "    # n-gram language model scoring\n",
    "    def prob(self, sentence):\n",
    "        return [10**i[0] for i in self.lm.full_scores(sentence,eos=False)][-1]\n",
    "\n",
    "    # word insertion term\n",
    "    def sent_len(self, sentence):\n",
    "        return len(sentence.strip().split(' '))\n",
    "\n",
    "    # reset alpha and beta\n",
    "    def reset_params(self, alpha, beta):\n",
    "        self.alpha, self.beta = alpha, beta\n",
    "\n",
    "    # execute evaluation\n",
    "    def __call__(self, sentence, log=False):\n",
    "        if self.alpha == 0 and self.beta == 0:\n",
    "            return 1.0\n",
    "        lm_score = self.prob(sentence)\n",
    "        word_insert_score = self.sent_len(sentence)\n",
    "#         print(sentence, lm_score, word_insert_score)\n",
    "        if log == False:\n",
    "            if sentence.strip().split(' ')[-1] not in self.lm:\n",
    "                    score = (np.power(lm_score, self.alpha) * np.power(word_insert_score, self.beta))*((0.1)**oov_weight)\n",
    "            else: score = np.power(lm_score, self.alpha) * np.power(word_insert_score, self.beta)\n",
    "        else:\n",
    "            if sentence.strip().split(' ')[-1] not in self.lm:\n",
    "                    score = self.alpha * np.log(lm_score) + self.beta * np.log(word_insert_score) - (10)**oov_weight\n",
    "            else: score = self.alpha * np.log(lm_score) + self.beta * np.log(word_insert_score)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beam search decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_bsp(out,labels,scorer,log=False,prune=0.00001,beam_size=25,alpha=1.45,beta=3,lm=None,w_t_o_b=250):\n",
    "    \n",
    "    blank_symbol = '_'\n",
    "    F = out.shape[1] # length of labels\n",
    "    steps = out.shape[0] # number of time steps\n",
    "    \n",
    "    t_b = [('', (1.0 ,0.0 ))] # beam at every time step gets updated\n",
    "    t_1 = None\n",
    "    \n",
    "    for t in tqdm(range(0,steps)):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t]>prune)[0]]\n",
    "        dummy_beam = defaultdict(lambda: (0,0))\n",
    "        dummy = t_b\n",
    "        for prefix, (pb,pnb) in t_b:\n",
    "            for c in pruned_alphabet:\n",
    "                p_t = out[t][labels.index(c)]\n",
    "                \n",
    "                if c == blank_symbol:\n",
    "                    dpb,dpnb = dummy_beam[prefix]\n",
    "                    dpb += p_t*(pb + pnb)\n",
    "                    dummy_beam[prefix] = (dpb,dpnb)\n",
    "                    continue\n",
    "                \n",
    "                end_t = prefix[-1] if prefix else None\n",
    "                c_t = prefix + c\n",
    "                dpb,dpnb = dummy_beam[c_t]\n",
    "                if c == end_t and len(prefix) > 0:\n",
    "                    dpb_,dpnb_ = dummy_beam[prefix]\n",
    "                    dpnb += p_t*pb\n",
    "                    dpnb_ += p_t*pnb\n",
    "                    dummy_beam[prefix] = (dpb_,dpnb_)\n",
    "                    \n",
    "                elif c == ' ' and len(prefix.strip().split(' ')) > 1:\n",
    "                    dpnb += p_t*(pb + pnb)*scorer(prefix)\n",
    "                \n",
    "                else:\n",
    "                    dpnb += p_t*(pb + pnb)\n",
    "                dummy_beam[c_t] = (dpb,dpnb)\n",
    "\n",
    "                if beam_size < w_t_o_b:\n",
    "                    if c_t not in t_b and t_1 != None:\n",
    "                        dpbn,dpnbn = dummy_beam[c_t]\n",
    "                        for i in t_1:\n",
    "                            if i[0] == c_t:\n",
    "                                b_, nb_  = i[1][0], i[1][1]\n",
    "                            else:\n",
    "                                b_, nb_  = 0, 0\n",
    "                        dpbn  += out[t][labels.index(\"_\")]*(b_ + nb_)\n",
    "                        dpnbn += p_t*nb_\n",
    "                        dummy_beam[c_t] = (dpbn,dpnbn)\n",
    "\n",
    "        t_1 = t_b\n",
    "        t_b = sorted(dummy_beam.items(),\n",
    "                      key=lambda x:np.sum(x[1]),\n",
    "                      reverse=True)\n",
    "        t_b = t_b[:beam_size]\n",
    "    \n",
    "    best = sorted([(scorer(i[0]),i[0]) for i in t_b],reverse=True)[0][1]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbc2a8d827e47b690c106628db22c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=681.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR MOREHOUSE TO RIDE WITH THEM TO THE KING'S  COURT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.564102564102564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha, beta, lm, oov_weight =1.99, 2, '/home/hemant/4_gram.arpa', 1\n",
    "scorer = Scorer(alpha,beta,lm,oov_weight)\n",
    "beam_txt = prefix_bsp(out,labels,scorer,log=False,prune=0.00001, beam_size=50,w_t_o_b=10)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.strip().split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR MARHAUS TO RIDE WITH THEM TO THE KING'S COURT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_bsl(out,labels,scorer,log=False,prune=0.00001,beam_size=20,alpha=0.01,beta=0,lm=None,w_t_o_b=10):\n",
    "    \n",
    "    blank_symbol = '_'\n",
    "    F = out.shape[1] # length of labels\n",
    "    steps = out.shape[0] # number of time steps\n",
    "    prob_ = out\n",
    "    out = np.log(out)\n",
    "    NEG_INF = -float(\"inf\")\n",
    "    \n",
    "    t_b = [('', (0.0, NEG_INF ))] # beam at every time step gets updated\n",
    "    t_1 = None\n",
    "    \n",
    "    for t in tqdm(range(0,steps)):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(prob_[t]>prune)[0]]\n",
    "        dummy_beam = defaultdict(lambda: (NEG_INF, NEG_INF))\n",
    "        dummy = t_b\n",
    "        for prefix, (pb,pnb) in t_b:\n",
    "            for c in pruned_alphabet:\n",
    "                p_t = out[t][labels.index(c)]\n",
    "                \n",
    "                if c == blank_symbol:\n",
    "                    dpb,dpnb = dummy_beam[prefix]\n",
    "                    dpb = lse(dpb, p_t+pb, p_t+pnb)\n",
    "                    dummy_beam[prefix] = (dpb,dpnb)\n",
    "                    continue\n",
    "                \n",
    "                end_t = prefix[-1] if prefix else None\n",
    "                c_t = prefix + c\n",
    "                dpb,dpnb = dummy_beam[c_t]\n",
    "                if c == end_t and len(prefix) > 0:\n",
    "                    dpb_,dpnb_ = dummy_beam[prefix]\n",
    "                    dpnb = lse(dpnb,p_t+pb)\n",
    "                    dpnb_ = lse(dpnb_,p_t+pnb)\n",
    "                    dummy_beam[prefix] = (dpb_,dpnb_)\n",
    "                    \n",
    "                elif c == ' ' and len(prefix.strip().split(' ')) > 1:\n",
    "                    score = scorer(prefix,log=True)\n",
    "                    if score == 1.0: dpnb = lse(dpnb,p_t+pb, p_t+pnb)\n",
    "                    else: \n",
    "                        dpnb = lse(dpnb,p_t+pb, p_t+pnb)\n",
    "                        dpnb = lse(dpnb,score)\n",
    "\n",
    "                else:\n",
    "                    dpnb = lse(dpnb, p_t+pb, p_t+ pnb)\n",
    "                dummy_beam[c_t] = (dpb,dpnb)\n",
    "                \n",
    "                if w_t_o_b < 50:\n",
    "                    if c_t not in t_b and t_1 != None:\n",
    "                        dpbn,dpnbn = dummy_beam[c_t]\n",
    "                        for i in t_1:\n",
    "                            if i[0] == c_t:\n",
    "                                b_, nb_  = i[1][0], i[1][1]\n",
    "                            else:\n",
    "                                b_, nb_  = NEG_INF, NEG_INF\n",
    "                        dpbn  = lse(dpbn,out[t][labels.index(\"_\")]+b_, out[t][labels.index(\"_\")]+ nb_)\n",
    "                        dpnbn = lse(dpnbn, p_t+nb_)\n",
    "                        dummy_beam[c_t] = (dpbn,dpnbn)\n",
    "\n",
    "        t_1 = t_b\n",
    "        t_b = sorted(dummy_beam.items(),\n",
    "                      key=lambda x:lse(*x[1]),\n",
    "                      reverse=True)\n",
    "        t_b = t_b[:beam_size]\n",
    "        \n",
    "\n",
    "    best = sorted([(scorer(i[0]),i[0]) for i in t_b],reverse=True)[0][1]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acdf52116af4ad982d107e0345e3888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=681.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND CHARGED IF EVER HE  MIGHT FIND SIR GAWAINE AND  SIR UWAINE  TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYD DHAS OR MORE HOUSE TO RIDE WITH THEM  TO THE KING'S COURT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.82051282051282"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha, beta, lm, oov_weight =1.96,3, '/home/hemant/asr_wm/lm/lm.binary', 1\n",
    "scorer = Scorer(alpha,beta,lm,oov_weight)\n",
    "beam_txt = prefix_bsl(out,labels,scorer,log=True,prune=0.00001, beam_size=10,w_t_o_b=100)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.strip().split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND CHARGED IF EVER HE MIGHT FIND SIR GAWAINE AND SIR UWAINE TO BRING THEM TO THE COURT AGAIN AND THEN WERE THEY ALL GLAD AND SO PRAYED THEY SIR MARHAUS TO RIDE WITH THEM TO THE KING'S COURT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
