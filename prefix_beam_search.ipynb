{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import json, pickle, os, string, tqdm, kenlm, json\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby\n",
    "import Levenshtein as Lev\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(*args): # logsumexp trick\n",
    "    a_max = max(args)\n",
    "    lsp = math.log(sum(math.exp(a-a_max) for a in args))\n",
    "    return a_max + lsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1 = True text\n",
    "#s2 = predicted text\n",
    "\n",
    "def wer_(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes the Word Error Rate, defined as the edit distance between the\n",
    "    two provided sentences after tokenizing to words.\n",
    "    Arguments:\n",
    "        s1 (string): space-separated sentence\n",
    "        s2 (string): space-separated sentence\n",
    "    \"\"\"\n",
    "\n",
    "    # build mapping of words to integers\n",
    "    b = set(s1.split() + s2.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    # map the words to a char array (Levenshtein packages only accepts\n",
    "    # strings)\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    \n",
    "    return Lev.distance(''.join(w1), ''.join(w2))\n",
    "\n",
    "def cer_(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes the Character Error Rate, defined as the edit distance.\n",
    "\n",
    "    Arguments:\n",
    "        s1 (string): space-separated sentence\n",
    "        s2 (string): space-separated sentence\n",
    "    \"\"\"\n",
    "    s1, s2, = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "\n",
    "    return Lev.distance(s1, s2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#When using the above implementation, use the code belove to calculate the wer in percentatge: \n",
    "#pred = list of ouput prediction of model (it is the text) # example [\" MY NAME IS HEMANT\", \" I AM A GOD\"]\n",
    "# total_wer = 0\n",
    "# for x in range(len(pred)):\n",
    "#     transcript, reference = data_[x][1], pred[x]\n",
    "#     wer_inst = wer(transcript, reference)\n",
    "#     total_wer += float(wer_inst)\n",
    "# print(\"WER is : \",total_wer/len(pred),\"%\")\n",
    "# wer_(pred,true)/len(pred.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load(\"out.npy\")\n",
    "with open(\"true.txt\", \"r\") as f:\n",
    "    reference = f.read()\n",
    "with open(\"pred.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_best_path(out,labels):\n",
    "    \"implements best path decoding as shown by Graves\"\n",
    "    out = [labels[i] for i in np.argmax(out, axis=1) if i!=labels[-1]]\n",
    "    o = \"\"\n",
    "    for i,j in groupby(out):\n",
    "        o = o + i\n",
    "    return o.replace(\"_\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR PRODATIVITY AND OUR COMMITMENT TO OUR CLIENTS XXXUM TO MAKE SURE THAT WE NEED WHAT BE XXXUM PROMISED FOR THE DEADLINE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.047619047619047"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gred_txt = ctc_best_path(out,labels)\n",
    "print(gred_txt)\n",
    "wer_(gred_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORD LM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_w = kenlm.LanguageModel('/home/hemant/sopi_deep/lm/3_gram_full.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "\n",
    "#using WORD LM\n",
    "def ctc_beam_search(out,labels, prune=0.0001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algo13.043478260869565%'rithm as shown by Graves\"\n",
    "    '''\n",
    "    out = ctc output\n",
    "    labels = string of labels\n",
    "    prune = prune the ctc output\n",
    "    k=beam-width\n",
    "    lm=word age model used\n",
    "    alpha,beta = hyper-parameters\n",
    "    '''\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            \n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] = out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    continue\n",
    "                else:\n",
    "                    i_plus = b + c_t\n",
    "                    if len(b) > 0 and c_t == b[-1]: #Extending with the same character as the last one\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #Extending case as the last character is different\n",
    "                    elif c_t == \" \" and len(b.replace(' ', '')) > 0 : # LM constraints\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = (10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])*(len(b.split())+1)**beta\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    # If the new beam is not in the previous beams\n",
    "                    if i_plus not in prev_beams:\n",
    "                        pb[t][i_plus] += out[t][labels.index(\"_\")] * (pb[t - 1][i_plus] + pnb[t - 1][i_plus])\n",
    "                        pnb[t][i_plus] += out[t][index] * pnb[t - 1][i_plus]\n",
    "\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR PRODUCTIVITY AND OUR COMMITMENT TO OUR CLIENTS XXXUM TO MAKE SURE THAT WE NEED WHAT WE XXXUM PROMISED FOR THE DEADLINE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.523809523809524"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_txt = ctc_beam_search(out,labels,0.0001,k=100,lm=lm_w,alpha=1.96,beta=6)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHARACTER LM Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_c = kenlm.LanguageModel('/home/hemant/E2E_NER-Through-Speech/LM/3_char_gram.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "#using CHARACTER LM\n",
    "def ctc_beam_search_clm(out,labels, prune=0.001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algorithm as shown by Graves\"\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])  \n",
    "                else:  # LM constraints\n",
    "                    i_plus = b + c_t\n",
    "                     #Extending with the same character as the last one\n",
    "                    if len(b) > 0 and c_t == b[-1]:\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #expanding the beam (extend case as the last character is different)\n",
    "                    elif len(b.replace(' ', '')) > 0 :\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = 1#(10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        for i in ptot.keys():\n",
    "            ptot[i] = ptot[i]*(len(i)+1)**beta\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMANTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/hemant/E2E_NER-Through-Speech/S2T/\")\n",
    "from opts import add_decoder_args, add_inference_args\n",
    "from utils import load_model\n",
    "import os\n",
    "from ctc_decoders import *\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from data.data_loader import SpectrogramParser\n",
    "\n",
    "from opts import add_decoder_args, add_inference_args\n",
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/654 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/654 [00:02<28:56,  2.66s/it]\u001b[A\n",
      "  0%|          | 2/654 [00:04<26:02,  2.40s/it]\u001b[A\n",
      "  0%|          | 3/654 [00:05<22:44,  2.10s/it]\u001b[A\n",
      "  1%|          | 4/654 [00:08<23:24,  2.16s/it]\u001b[A\n",
      "  1%|          | 5/654 [00:11<25:59,  2.40s/it]\u001b[A\n",
      "  1%|          | 6/654 [00:13<25:17,  2.34s/it]\u001b[A\n",
      "  1%|          | 7/654 [00:15<23:30,  2.18s/it]\u001b[A\n",
      "  1%|          | 8/654 [00:16<22:18,  2.07s/it]\u001b[A\n",
      "  1%|▏         | 9/654 [00:19<24:24,  2.27s/it]\u001b[A\n",
      "  2%|▏         | 10/654 [00:21<23:48,  2.22s/it]\u001b[A\n",
      "  2%|▏         | 11/654 [00:23<22:27,  2.10s/it]\u001b[A\n",
      "  2%|▏         | 12/654 [00:24<18:28,  1.73s/it]\u001b[A\n",
      "  2%|▏         | 13/654 [00:26<19:04,  1.78s/it]\u001b[A\n",
      "  2%|▏         | 14/654 [00:28<19:50,  1.86s/it]\u001b[A\n",
      "  2%|▏         | 15/654 [00:30<21:32,  2.02s/it]\u001b[A\n",
      "  2%|▏         | 16/654 [00:33<22:52,  2.15s/it]\u001b[A\n",
      "  3%|▎         | 17/654 [00:34<20:42,  1.95s/it]\u001b[A\n",
      "  3%|▎         | 18/654 [00:37<22:40,  2.14s/it]\u001b[A\n",
      "  3%|▎         | 19/654 [00:39<23:21,  2.21s/it]\u001b[A\n",
      "  3%|▎         | 20/654 [00:41<21:25,  2.03s/it]\u001b[A\n",
      "  3%|▎         | 21/654 [00:45<26:55,  2.55s/it]\u001b[A\n",
      "  3%|▎         | 22/654 [00:46<24:33,  2.33s/it]\u001b[A\n",
      "  4%|▎         | 23/654 [00:49<26:26,  2.51s/it]\u001b[A\n",
      "  4%|▎         | 24/654 [00:51<24:15,  2.31s/it]\u001b[A\n",
      "  4%|▍         | 25/654 [00:52<20:11,  1.93s/it]\u001b[A\n",
      "  4%|▍         | 26/654 [00:54<18:41,  1.79s/it]\u001b[A\n",
      "  4%|▍         | 27/654 [00:56<19:54,  1.91s/it]\u001b[A\n",
      "  4%|▍         | 28/654 [00:58<20:11,  1.94s/it]\u001b[A\n",
      "  4%|▍         | 29/654 [00:59<18:14,  1.75s/it]\u001b[A\n",
      "  5%|▍         | 30/654 [01:01<19:28,  1.87s/it]\u001b[A\n",
      "  5%|▍         | 31/654 [01:03<17:20,  1.67s/it]\u001b[A\n",
      "  5%|▍         | 32/654 [01:04<15:28,  1.49s/it]\u001b[A\n",
      "  5%|▌         | 33/654 [01:05<15:37,  1.51s/it]\u001b[A\n",
      "  5%|▌         | 34/654 [01:06<14:07,  1.37s/it]\u001b[A\n",
      "  5%|▌         | 35/654 [01:08<16:38,  1.61s/it]\u001b[A\n",
      "  6%|▌         | 36/654 [01:10<16:15,  1.58s/it]\u001b[A\n",
      "  6%|▌         | 37/654 [01:11<14:39,  1.43s/it]\u001b[A\n",
      "  6%|▌         | 38/654 [01:13<15:17,  1.49s/it]\u001b[A\n",
      "  6%|▌         | 39/654 [01:15<18:32,  1.81s/it]\u001b[A\n",
      "  6%|▌         | 40/654 [01:17<17:37,  1.72s/it]\u001b[A\n",
      "  6%|▋         | 41/654 [01:19<20:25,  2.00s/it]\u001b[A\n",
      "  6%|▋         | 42/654 [01:21<19:35,  1.92s/it]\u001b[A\n",
      "  7%|▋         | 43/654 [01:23<19:21,  1.90s/it]\u001b[A\n",
      "  7%|▋         | 44/654 [01:25<19:57,  1.96s/it]\u001b[A\n",
      "  7%|▋         | 45/654 [01:27<18:59,  1.87s/it]\u001b[A\n",
      "  7%|▋         | 46/654 [01:28<16:41,  1.65s/it]\u001b[A\n",
      "  7%|▋         | 47/654 [01:29<15:40,  1.55s/it]\u001b[A\n",
      "  7%|▋         | 48/654 [01:31<15:58,  1.58s/it]\u001b[A\n",
      "  7%|▋         | 49/654 [01:33<17:45,  1.76s/it]\u001b[A\n",
      "  8%|▊         | 50/654 [01:35<19:16,  1.91s/it]\u001b[A\n",
      "  8%|▊         | 51/654 [01:36<15:53,  1.58s/it]\u001b[A\n",
      "  8%|▊         | 52/654 [01:38<18:07,  1.81s/it]\u001b[A\n",
      "  8%|▊         | 53/654 [01:40<16:32,  1.65s/it]\u001b[A\n",
      "  8%|▊         | 54/654 [01:42<17:31,  1.75s/it]\u001b[A\n",
      "  8%|▊         | 55/654 [01:43<17:06,  1.71s/it]\u001b[A\n",
      "  9%|▊         | 56/654 [01:45<16:32,  1.66s/it]\u001b[A\n",
      "  9%|▊         | 57/654 [01:46<15:21,  1.54s/it]\u001b[A\n",
      "  9%|▉         | 58/654 [01:48<15:26,  1.55s/it]\u001b[A\n",
      "  9%|▉         | 59/654 [01:49<14:22,  1.45s/it]\u001b[A\n",
      "  9%|▉         | 60/654 [01:50<14:22,  1.45s/it]\u001b[A\n",
      "  9%|▉         | 61/654 [01:52<13:48,  1.40s/it]\u001b[A\n",
      "  9%|▉         | 62/654 [01:53<12:43,  1.29s/it]\u001b[A\n",
      " 10%|▉         | 63/654 [01:54<12:27,  1.27s/it]\u001b[A\n",
      " 10%|▉         | 64/654 [01:55<11:23,  1.16s/it]\u001b[A\n",
      " 10%|▉         | 65/654 [01:56<11:28,  1.17s/it]\u001b[A\n",
      " 10%|█         | 66/654 [01:57<11:40,  1.19s/it]\u001b[A\n",
      " 10%|█         | 67/654 [01:58<10:58,  1.12s/it]\u001b[A\n",
      " 10%|█         | 68/654 [01:59<10:21,  1.06s/it]\u001b[A\n",
      " 11%|█         | 69/654 [02:00<11:24,  1.17s/it]\u001b[A\n",
      " 11%|█         | 70/654 [02:02<13:18,  1.37s/it]\u001b[A\n",
      " 11%|█         | 71/654 [02:03<12:23,  1.28s/it]\u001b[A\n",
      " 11%|█         | 72/654 [02:05<14:47,  1.52s/it]\u001b[A\n",
      " 11%|█         | 73/654 [02:06<12:03,  1.24s/it]\u001b[A\n",
      " 11%|█▏        | 74/654 [02:07<11:10,  1.16s/it]\u001b[A\n",
      " 11%|█▏        | 75/654 [02:09<13:07,  1.36s/it]\u001b[A\n",
      " 12%|█▏        | 76/654 [02:10<12:18,  1.28s/it]\u001b[A\n",
      " 12%|█▏        | 77/654 [02:11<10:49,  1.13s/it]\u001b[A\n",
      " 12%|█▏        | 78/654 [02:12<12:11,  1.27s/it]\u001b[A\n",
      " 12%|█▏        | 79/654 [02:13<10:29,  1.10s/it]\u001b[A\n",
      " 12%|█▏        | 80/654 [02:14<09:51,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 81/654 [02:15<09:58,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 82/654 [02:16<10:41,  1.12s/it]\u001b[A\n",
      " 13%|█▎        | 83/654 [02:18<11:11,  1.18s/it]\u001b[A\n",
      " 13%|█▎        | 84/654 [02:18<09:51,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 85/654 [02:20<10:34,  1.12s/it]\u001b[A\n",
      " 13%|█▎        | 86/654 [02:20<09:50,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 87/654 [02:21<09:30,  1.01s/it]\u001b[A\n",
      " 13%|█▎        | 88/654 [02:22<09:00,  1.05it/s]\u001b[A\n",
      " 14%|█▎        | 89/654 [02:23<08:33,  1.10it/s]\u001b[A\n",
      " 14%|█▍        | 90/654 [02:25<10:23,  1.10s/it]\u001b[A\n",
      " 14%|█▍        | 91/654 [02:26<12:01,  1.28s/it]\u001b[A\n",
      " 14%|█▍        | 92/654 [02:27<11:39,  1.24s/it]\u001b[A\n",
      " 14%|█▍        | 93/654 [02:29<12:19,  1.32s/it]\u001b[A\n",
      " 14%|█▍        | 94/654 [02:30<11:47,  1.26s/it]\u001b[A\n",
      " 15%|█▍        | 95/654 [02:31<09:53,  1.06s/it]\u001b[A\n",
      " 15%|█▍        | 96/654 [02:32<10:28,  1.13s/it]\u001b[A\n",
      " 15%|█▍        | 97/654 [02:33<11:26,  1.23s/it]\u001b[A\n",
      " 15%|█▍        | 98/654 [02:35<11:20,  1.22s/it]\u001b[A\n",
      " 15%|█▌        | 99/654 [02:36<12:04,  1.31s/it]\u001b[A\n",
      " 15%|█▌        | 100/654 [02:37<12:18,  1.33s/it]\u001b[A\n",
      " 15%|█▌        | 101/654 [02:39<13:09,  1.43s/it]\u001b[A\n",
      " 16%|█▌        | 102/654 [02:40<12:20,  1.34s/it]\u001b[A\n",
      " 16%|█▌        | 103/654 [02:42<13:44,  1.50s/it]\u001b[A\n",
      " 16%|█▌        | 104/654 [02:43<13:23,  1.46s/it]\u001b[A\n",
      " 16%|█▌        | 105/654 [02:46<16:27,  1.80s/it]\u001b[A\n",
      " 16%|█▌        | 106/654 [02:48<17:49,  1.95s/it]\u001b[A\n",
      " 16%|█▋        | 107/654 [02:49<15:07,  1.66s/it]\u001b[A\n",
      " 17%|█▋        | 108/654 [02:51<13:49,  1.52s/it]\u001b[A\n",
      " 17%|█▋        | 109/654 [02:51<12:12,  1.34s/it]\u001b[A\n",
      " 17%|█▋        | 110/654 [02:53<11:32,  1.27s/it]\u001b[A\n",
      " 17%|█▋        | 111/654 [02:54<11:28,  1.27s/it]\u001b[A\n",
      " 17%|█▋        | 112/654 [02:55<11:12,  1.24s/it]\u001b[A\n",
      " 17%|█▋        | 113/654 [02:56<10:50,  1.20s/it]\u001b[A\n",
      " 17%|█▋        | 114/654 [02:57<08:45,  1.03it/s]\u001b[A\n",
      " 18%|█▊        | 115/654 [02:58<10:54,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 116/654 [03:00<11:29,  1.28s/it]\u001b[A\n",
      " 18%|█▊        | 117/654 [03:01<12:09,  1.36s/it]\u001b[A\n",
      " 18%|█▊        | 118/654 [03:02<11:02,  1.24s/it]\u001b[A\n",
      " 18%|█▊        | 119/654 [03:03<10:31,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 120/654 [03:05<10:40,  1.20s/it]\u001b[A\n",
      " 19%|█▊        | 121/654 [03:05<08:42,  1.02it/s]\u001b[A\n",
      " 19%|█▊        | 122/654 [03:06<08:47,  1.01it/s]\u001b[A\n",
      " 19%|█▉        | 123/654 [03:07<09:48,  1.11s/it]\u001b[A\n",
      " 19%|█▉        | 124/654 [03:10<13:57,  1.58s/it]\u001b[A\n",
      " 19%|█▉        | 125/654 [03:11<13:13,  1.50s/it]\u001b[A\n",
      " 19%|█▉        | 126/654 [03:13<14:17,  1.62s/it]\u001b[A\n",
      " 19%|█▉        | 127/654 [03:15<14:05,  1.60s/it]\u001b[A\n",
      " 20%|█▉        | 128/654 [03:17<14:32,  1.66s/it]\u001b[A\n",
      " 20%|█▉        | 129/654 [03:18<13:43,  1.57s/it]\u001b[A\n",
      " 20%|█▉        | 130/654 [03:19<12:14,  1.40s/it]\u001b[A\n",
      " 20%|██        | 131/654 [03:20<11:26,  1.31s/it]\u001b[A\n",
      " 20%|██        | 132/654 [03:22<11:38,  1.34s/it]\u001b[A\n",
      " 20%|██        | 133/654 [03:23<11:41,  1.35s/it]\u001b[A\n",
      " 20%|██        | 134/654 [03:25<12:41,  1.46s/it]\u001b[A\n",
      " 21%|██        | 135/654 [03:26<11:56,  1.38s/it]\u001b[A\n",
      " 21%|██        | 136/654 [03:28<13:06,  1.52s/it]\u001b[A\n",
      " 21%|██        | 137/654 [03:30<14:09,  1.64s/it]\u001b[A\n",
      " 21%|██        | 138/654 [03:31<14:25,  1.68s/it]\u001b[A\n",
      " 21%|██▏       | 139/654 [03:34<17:40,  2.06s/it]\u001b[A\n",
      " 21%|██▏       | 140/654 [03:35<15:13,  1.78s/it]\u001b[A\n",
      " 22%|██▏       | 141/654 [03:38<15:56,  1.86s/it]\u001b[A\n",
      " 22%|██▏       | 142/654 [03:38<13:38,  1.60s/it]\u001b[A\n",
      " 22%|██▏       | 143/654 [03:40<13:36,  1.60s/it]\u001b[A\n",
      " 22%|██▏       | 144/654 [03:41<11:59,  1.41s/it]\u001b[A\n",
      " 22%|██▏       | 145/654 [03:42<11:34,  1.37s/it]\u001b[A\n",
      " 22%|██▏       | 146/654 [03:44<11:28,  1.35s/it]\u001b[A\n",
      " 22%|██▏       | 147/654 [03:45<10:40,  1.26s/it]\u001b[A\n",
      " 23%|██▎       | 148/654 [03:46<10:29,  1.24s/it]\u001b[A\n",
      " 23%|██▎       | 149/654 [03:47<09:51,  1.17s/it]\u001b[A\n",
      " 23%|██▎       | 150/654 [03:48<09:16,  1.10s/it]\u001b[A\n",
      " 23%|██▎       | 151/654 [03:49<09:27,  1.13s/it]\u001b[A\n",
      " 23%|██▎       | 152/654 [03:50<09:14,  1.10s/it]\u001b[A\n",
      " 23%|██▎       | 153/654 [03:53<13:28,  1.61s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# decoding = 'greedy'\n",
    "decoding = 'beam_w'\n",
    "# decoding = 'beam_c'\n",
    "prune = 0.0001\n",
    "beam_width = 100\n",
    "alpha = 1.4\n",
    "beta = 4\n",
    "lm = lm_w\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\")\n",
    "model = load_model(device, \"/home/hemant/sopi_deep/models/deep/finetuen_sopi.pth\")\n",
    "spect_parser = SpectrogramParser(model.audio_conf, normalize=True)\n",
    "\n",
    "torch.cuda.set_device(int(0))\n",
    "with open(\"/home/hemant/sopi_deep/data/deepspeech/test/data.csv\",\"r\") as f:\n",
    "    csv = f.readlines()\n",
    "\n",
    "total_cer, total_wer, num_tokens, num_chars = 0, 0, 0, 0\n",
    "lm = lm_w\n",
    "output = []\n",
    "for i in tqdm(csv):\n",
    "    audio_path, reference_path = i.split(\",\")\n",
    "\n",
    "    spect = spect_parser.parse_audio(audio_path).contiguous()\n",
    "    spect = spect.view(1, 1, spect.size(0), spect.size(1))\n",
    "    spect = spect.to(device)\n",
    "\n",
    "    input_sizes = torch.IntTensor([spect.size(3)]).int()\n",
    "    out, output_sizes = model(spect, input_sizes)\n",
    "    out = out.cpu().detach().numpy()[0]\n",
    "\n",
    "    if decoding == \"greedy\": transcript = ctc_best_path(out,labels)\n",
    "    elif decoding == \"beam_w\": transcript = ctc_beam_search(out,labels,prune,beam_width,lm,alpha,beta)\n",
    "    elif decoding == \"beam_c\": transcript = ctc_beam_search_clm(out,labels,prune,beam_width,lm,alpha=alpha,beta=beta)\n",
    "        \n",
    "    with open(reference_path.replace(\"\\n\",\"\"),\"r\") as f:\n",
    "        reference = f.readline()\n",
    "    output.append([transcript,reference])\n",
    "    wer_inst = wer_(transcript,reference)\n",
    "    cer_inst = cer_(transcript, reference)\n",
    "    total_wer += wer_inst\n",
    "    total_cer += cer_inst\n",
    "    num_tokens += len(reference.split(' '))\n",
    "    num_chars += len(reference.replace(' ', ''))\n",
    "        \n",
    "wer = (float(total_wer) / num_tokens)*100\n",
    "cer = (float(total_cer) / num_chars)*100\n",
    "print('Test Summary \\t'\n",
    "    'Average WER {wer:.3f}\\t'\n",
    "    'Average CER {cer:.3f}\\t'.format(wer=wer, cer=cer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy 39.850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beam 49.969   1.96 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "\n",
    "#using WORD LM\n",
    "def ctc_beam_search(out,labels, prune=0.0001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algo13.043478260869565%'rithm as shown by Graves\"\n",
    "    '''\n",
    "    out = ctc output\n",
    "    labels = string of labels\n",
    "    prune = prune the ctc output\n",
    "    k=beam-width\n",
    "    lm=word age model used\n",
    "    alpha,beta = hyper-parameters\n",
    "    '''\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            \n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] = out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    continue\n",
    "                else:\n",
    "                    i_plus = b + c_t\n",
    "                    if len(b) > 0 and c_t == b[-1]: #Extending with the same character as the last one\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #Extending case as the last character is different\n",
    "                    elif c_t == \" \" and len(b.replace(' ', '')) > 0 : # LM constraints\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = (10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])*(len(b.split())+1)**beta\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    # If the new beam is not in the previous beams\n",
    "                    if i_plus not in prev_beams:\n",
    "                        pb[t][i_plus] += out[t][labels.index(\"_\")] * (pb[t - 1][i_plus] + pnb[t - 1][i_plus])\n",
    "                        pnb[t][i_plus] += out[t][index] * pnb[t - 1][i_plus]\n",
    "\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\")\n",
    "model = load_model(device, \"/home/hemant/sopi_deep/models/deep/finetuen_sopi.pth\")\n",
    "spect_parser = SpectrogramParser(model.audio_conf, normalize=True)\n",
    "\n",
    "torch.cuda.set_device(int(0))\n",
    "with open(\"/home/hemant/sopi_deep/data/deepspeech/test/data.csv\",\"r\") as f:\n",
    "    csv = f.readlines()\n",
    "    \n",
    "# decoding = 'greedy'\n",
    "decoding = 'beam_w'\n",
    "# decoding = 'beam_c'\n",
    "prune = 0.0001\n",
    "beam_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha, beta = np.linspace(0.2,2,15), np.linspace(0,6,15)\n",
    "values = [[i,j] for j in beta for i in alpha]\n",
    "\n",
    "total_cer, total_wer, num_tokens, num_chars = 0, 0, 0, 0\n",
    "lm = lm_w\n",
    "output = []\n",
    "\n",
    "for alpha,beta in tqdm(values):\n",
    "    for i in csv:\n",
    "        audio_path, reference_path = i.split(\",\")\n",
    "\n",
    "        spect = spect_parser.parse_audio(audio_path).contiguous()\n",
    "        spect = spect.view(1, 1, spect.size(0), spect.size(1))\n",
    "        spect = spect.to(device)\n",
    "\n",
    "        input_sizes = torch.IntTensor([spect.size(3)]).int()\n",
    "        out, output_sizes = model(spect, input_sizes)\n",
    "        out = out.cpu().detach().numpy()[0]\n",
    "\n",
    "        if decoding == \"greedy\": transcript = ctc_best_path(out,labels)\n",
    "        elif decoding == \"beam_w\": transcript = ctc_beam_search(out,labels,prune,beam_width,lm,alpha,beta)\n",
    "        elif decoding == \"beam_c\": transcript = ctc_beam_search_clm(out,labels,prune,beam_width,lm,alpha=alpha,beta=beta)\n",
    "\n",
    "        with open(reference_path.replace(\"\\n\",\"\"),\"r\") as f:\n",
    "            reference = f.readline()\n",
    "        wer_inst = wer_(transcript,reference)\n",
    "        cer_inst = cer_(transcript, reference)\n",
    "        total_wer += wer_inst\n",
    "        total_cer += cer_inst\n",
    "        num_tokens += len(reference.split(' '))\n",
    "        num_chars += len(reference.replace(' ', ''))\n",
    "    np.save(\"/home/hemant/ctc_decoders/abw.npy\",np.array(output))\n",
    "    wer = (float(total_wer) / num_tokens)*100\n",
    "    cer = (float(total_cer) / num_chars)*100\n",
    "    output.append([alpha,beta,wer])\n",
    "    print(\"aplha: \",alpha,\"beta: \",beta)\n",
    "    print('Test Summary \\t'\n",
    "        'Average WER {wer:.3f}\\t'\n",
    "        'Average CER {cer:.3f}\\t'.format(wer=wer, cer=cer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in output:\n",
    "    a.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in output:\n",
    "    if i[2] <= min(a):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/home/hemant/ctc_decoders/abw.npy\",np.array(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load(\"abw.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Summary    Average WER 27.562      Average CER 18.691 # beam deafult wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Summary \tAverage WER 42.638\tAverage CER 21.520 # beam wrote wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Summary \tAverage WER 48.410\tAverage CER 24.264\t greedy matches with the default wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_path,reference_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = audio_path + \",\" +reference_path\n",
    "# with open(\"/home/hemant/junk/out.csv\",\"w\") as f:\n",
    "#     f.write(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wer_(transcript,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
