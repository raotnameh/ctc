{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import json, pickle, os, string, tqdm, kenlm, json\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby\n",
    "import Levenshtein as Lev\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(*args): # logsumexp trick\n",
    "    a_max = max(args)\n",
    "    lsp = math.log(sum(math.exp(a-a_max) for a in args))\n",
    "    return a_max + lsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1 = True text\n",
    "#s2 = predicted text\n",
    "\n",
    "def wer_(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes the Word Error Rate, defined as the edit distance between the\n",
    "    two provided sentences after tokenizing to words.\n",
    "    Arguments:\n",
    "        s1 (string): space-separated sentence\n",
    "        s2 (string): space-separated sentence\n",
    "    \"\"\"\n",
    "\n",
    "    # build mapping of words to integers\n",
    "    b = set(s1.split() + s2.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    # map the words to a char array (Levenshtein packages only accepts\n",
    "    # strings)\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    \n",
    "    return Lev.distance(''.join(w1), ''.join(w2))\n",
    "\n",
    "def cer_(s1, s2):\n",
    "    \"\"\"\n",
    "    Computes the Character Error Rate, defined as the edit distance.\n",
    "\n",
    "    Arguments:\n",
    "        s1 (string): space-separated sentence\n",
    "        s2 (string): space-separated sentence\n",
    "    \"\"\"\n",
    "    s1, s2, = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "\n",
    "    return Lev.distance(s1, s2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#When using the above implementation, use the code belove to calculate the wer in percentatge: \n",
    "#pred = list of ouput prediction of model (it is the text) # example [\" MY NAME IS HEMANT\", \" I AM A GOD\"]\n",
    "# total_wer = 0\n",
    "# for x in range(len(pred)):\n",
    "#     transcript, reference = data_[x][1], pred[x]\n",
    "#     wer_inst = wer(transcript, reference)\n",
    "#     total_wer += float(wer_inst)\n",
    "# print(\"WER is : \",total_wer/len(pred),\"%\")\n",
    "# wer_(pred,true)/len(pred.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_best_path(out,labels):\n",
    "    \"implements best path decoding as shown by Graves\"\n",
    "    out = [labels[i] for i in np.argmax(out, axis=1) if i!=labels[-1]]\n",
    "    o = \"\"\n",
    "    for i,j in groupby(out):\n",
    "        o = o + i\n",
    "    return o.replace(\"_\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORD LM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_w = kenlm.LanguageModel('/home/hemant/E2E_NER-Through-Speech/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "\n",
    "#using WORD LM\n",
    "def ctc_beam_search(out,labels, prune=0.0001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algo13.043478260869565%'rithm as shown by Graves\"\n",
    "    '''\n",
    "    out = ctc output\n",
    "    labels = string of labels\n",
    "    prune = prune the ctc output\n",
    "    k=beam-width\n",
    "    lm=word age model used\n",
    "    alpha,beta = hyper-parameters\n",
    "    '''\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])   \n",
    "                else:\n",
    "                    i_plus = b + c_t\n",
    "                    if len(b) > 0 and c_t == b[-1]: #Extending with the same character as the last one\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #expanding the beam (extend case as the last character is different)\n",
    "                    elif c_t == \" \" and len(b.replace(' ', '')) > 0 : # LM constraints\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = (10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                        \n",
    "                    if i_plus not in prev_beams:\n",
    "                        pb[t][i_plus] += out[t][index] * (pb[t - 1][i_plus] + pnb[t - 1][i_plus])\n",
    "                        pnb[t][i_plus] += out[t][index] * pnb[t - 1][i_plus]\n",
    "\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        for i in ptot.keys():\n",
    "            ptot[i] = ptot[i]*(len(i)+1)**beta\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHARACTER LM Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_c = kenlm.LanguageModel('/home/hemant/E2E_NER-Through-Speech/LM/3_char_gram.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "#using CHARACTER LM\n",
    "def ctc_beam_search_clm(out,labels, prune=0.001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algorithm as shown by Graves\"\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])  \n",
    "                else:  # LM constraints\n",
    "                    i_plus = b + c_t\n",
    "                     #Extending with the same character as the last one\n",
    "                    if len(b) > 0 and c_t == b[-1]:\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #expanding the beam (extend case as the last character is different)\n",
    "                    elif len(b.replace(' ', '')) > 0 :\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = 1#(10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        for i in ptot.keys():\n",
    "            ptot[i] = ptot[i]*(len(i)+1)**beta\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMANTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/hemant/E2E_NER-Through-Speech/S2T/\")\n",
    "from opts import add_decoder_args, add_inference_args\n",
    "from utils import load_model\n",
    "import os\n",
    "from ctc_decoders import *\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from data.data_loader import SpectrogramParser\n",
    "\n",
    "from opts import add_decoder_args, add_inference_args\n",
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary \tAverage WER 72.000\tAverage CER 28.117\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# decoding = 'greedy'\n",
    "decoding = 'beam_w'\n",
    "# decoding = 'beam_c'\n",
    "prune = 0.0001\n",
    "beam_width = 100\n",
    "alpha = 1.02\n",
    "beta = 12\n",
    "lm = lm_w\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\")\n",
    "model = load_model(device, \"/home/hemant/sopi_deep/models/deep/finetuen_sopi.pth\")\n",
    "spect_parser = SpectrogramParser(model.audio_conf, normalize=True)\n",
    "\n",
    "torch.cuda.set_device(int(0))\n",
    "with open(\"/home/hemant/sopi_deep/data/deepspeech/test/ata/test.csv\",\"r\") as f:\n",
    "    csv = f.readlines()\n",
    "\n",
    "total_cer, total_wer, num_tokens, num_chars = 0, 0, 0, 0\n",
    "lm = lm_w\n",
    "output = []\n",
    "for i in tqdm(csv[:5]):\n",
    "    audio_path, reference_path = i.split(\",\")\n",
    "\n",
    "    spect = spect_parser.parse_audio(audio_path).contiguous()\n",
    "    spect = spect.view(1, 1, spect.size(0), spect.size(1))\n",
    "    spect = spect.to(device)\n",
    "\n",
    "    input_sizes = torch.IntTensor([spect.size(3)]).int()\n",
    "    out, output_sizes = model(spect, input_sizes)\n",
    "    out = out.cpu().detach().numpy()[0]\n",
    "\n",
    "    if decoding == \"greedy\": transcript = ctc_best_path(out,labels)\n",
    "    elif decoding == \"beam_w\": transcript = ctc_beam_search(out,labels,prune,beam_width,lm,alpha,beta)\n",
    "    elif decoding == \"beam_c\": transcript = ctc_beam_search_clm(out,labels,prune,beam_width,lm,alpha=alpha,beta=beta)\n",
    "        \n",
    "    with open(reference_path.replace(\"\\n\",\"\"),\"r\") as f:\n",
    "        reference = f.readline()\n",
    "    output.append([transcript,reference])\n",
    "    wer_inst = wer_(transcript,reference)\n",
    "    cer_inst = cer_(transcript, reference)\n",
    "    total_wer += wer_inst\n",
    "    total_cer += cer_inst\n",
    "    num_tokens += len(reference.split(' '))\n",
    "    num_chars += len(reference.replace(' ', ''))\n",
    "        \n",
    "wer = (float(total_wer) / num_tokens)*100\n",
    "cer = (float(total_cer) / num_chars)*100\n",
    "print('Test Summary \\t'\n",
    "    'Average WER {wer:.3f}\\t'\n",
    "    'Average CER {cer:.3f}\\t'.format(wer=wer, cer=cer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/hemant/sopi_deep/data/deepspeech/test/wav/en-122331-20191109-vyy-1251-1364.wav',\n",
       " '/home/hemant/sopi_deep/data/deepspeech/test/txt/en-122331-20191109-vyy-1251-1364.txt\\n')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path,reference_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = audio_path + \",\" +reference_path\n",
    "with open(\"/home/hemant/junk/out.csv\",\"w\") as f:\n",
    "    f.write(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_(transcript,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR PRODATIVITY AND OUR COMMITMENT TO OUR CLIENTS XXXUM TO MAKE SURE THAT WE NEED WHAT BE XXXUM PROMISED FOR THE DEADLINE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.047619047619047"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gred_txt = ctc_best_path(out,labels)\n",
    "print(gred_txt)\n",
    "wer_(gred_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR PRODUCTIVITY AND OUR COMMITMENT TO OUR CLIENTS XXXUM TO MAKE SURE THAT WE NEED WHAT WE XXXUM PROMISED FOR THE DEADLINE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.523809523809524"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_txt=ctc_beam_search(out,labels,0.0001,k=100,lm=lm_w,alpha=1.2,beta=12)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_txt=ctc_beam_search(out,labels,0.001,k=100,lm=lm_w,alpha=0,beta=0)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-b55abb770af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeam_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctc_beam_search_clm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwer_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_txt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm_c' is not defined"
     ]
    }
   ],
   "source": [
    "beam_txt=ctc_beam_search_clm(out,labels,0,k=10, lm_c = lm_c, alpha=0.1,beta=6)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    output.append([transcript,reference])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "\n",
    "NEG_INF = -float(\"inf\")\n",
    "\n",
    "def make_new_beam():\n",
    "  fn = lambda : (NEG_INF, NEG_INF)\n",
    "  return collections.defaultdict(fn)\n",
    "\n",
    "def logsumexp(*args):\n",
    "  \"\"\"\n",
    "  Stable log sum exp.\n",
    "  \"\"\"\n",
    "  if all(a == NEG_INF for a in args):\n",
    "      return NEG_INF\n",
    "  a_max = max(args)\n",
    "  lsp = math.log(sum(math.exp(a - a_max)\n",
    "                      for a in args))\n",
    "  return a_max + lsp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_beam(ptot,k):\n",
    "    if len(ptot) < k:\n",
    "        return [i for i in ptot.keys()]\n",
    "    else:\n",
    "        dict_ = sorted(dict((v,k) for k,v in ptot.items()).items(),reverse=True)[:k]\n",
    "        return [i[1] for i in dict_]\n",
    "\n",
    "#using WORD LM\n",
    "def ctc_beam_search(out,labels, prune=0.0001, k=20, lm=None,alpha=0.3,beta=12):\n",
    "    \"implements CTC Prefix Search Decoding Algo13.043478260869565%'rithm as shown by Graves\"\n",
    "\n",
    "    bc_i = 0 # blank/special charatcter index \n",
    "    F = out.shape[1]\n",
    "    out = np.vstack((np.zeros(F), out))\n",
    "    steps = out.shape[0]\n",
    "    \n",
    "    pb, pnb = defaultdict(Counter), defaultdict(Counter)\n",
    "    pb[0][''], pnb[0][''] = 1, 0\n",
    "    prev_beams = ['']\n",
    "    for t in range(1,steps):\n",
    "        pruned_alphabet = [labels[i] for i in np.where(out[t] > prune)[0]]\n",
    "        for b in prev_beams:\n",
    "            for c_t in pruned_alphabet:\n",
    "                index = labels.index(c_t)\n",
    "                #Collapsing case (copy case as the last character in the beam)\n",
    "                if c_t == \"_\": #Extending with a blank\n",
    "                    pb[t][b] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])   \n",
    "                else:\n",
    "                    i_plus = b + c_t\n",
    "                    if len(b) > 0 and c_t == b[-1]: #Extending with the same character as the last one\n",
    "                        pnb[t][b] += out[t][index]*pnb[t-1][b]\n",
    "                        pnb[t][i_plus] += out[t][index]*pb[t-1][b]\n",
    "                    #expanding the beam (extend case as the last character is different)\n",
    "                    elif c_t == \" \" and len(b.replace(' ', '')) > 0 : # LM constraints\n",
    "                        prob = [i[0] for i in lm.full_scores(i_plus,eos=False,bos=False)][-1]\n",
    "                        lm_p = (10**prob)**alpha\n",
    "                        pnb[t][i_plus] += lm_p*out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                    else:\n",
    "                        pnb[t][i_plus] += out[t][index]*(pb[t-1][b] + pnb[t-1][b])\n",
    "                        \n",
    "                    if i_plus not in prev_beams:\n",
    "                        pb[t][i_plus] += out[t][index] * (pb[t - 1][i_plus] + pnb[t - 1][i_plus])\n",
    "                        pnb[t][i_plus] += out[t][index] * pnb[t - 1][i_plus]\n",
    "\n",
    "\n",
    "        ptot = pb[t] + pnb[t]\n",
    "        for i in ptot.keys():\n",
    "            ptot[i] = ptot[i]*(len(i)+1)**beta\n",
    "        prev_beams = sort_beam(ptot,k)\n",
    "    return prev_beams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I THINK IS IS GOINGNA BE VORY ALD IDEA IN THE BEAST IN INTELLETION ALDATI BUSINESSES IN THE YEARS TO COME I DONTWT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46.15384615384615"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_txt=ctc_beam_search(out,labels,0,k=1,lm=lm_w,alpha=0,beta=0)\n",
    "print(beam_txt)\n",
    "wer_(beam_txt,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode(probs, beam_size=100, blank=0):\n",
    "\n",
    "  T, S = probs.shape\n",
    "  probs = np.log(probs)\n",
    "\n",
    "  beam = [(tuple(), (0.0, NEG_INF))]\n",
    "\n",
    "  for t in range(T): # Loop over time\n",
    "    next_beam = make_new_beam()\n",
    "\n",
    "    for s in range(S): # Loop over vocab\n",
    "      p = probs[t, s]\n",
    "      for prefix, (p_b, p_nb) in beam: # Loop over beam\n",
    "        if s == blank:\n",
    "            n_p_b, n_p_nb = next_beam[prefix]\n",
    "            n_p_b = logsumexp(n_p_b, p_b + p, p_nb + p)\n",
    "            next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "            continue\n",
    "        end_t = prefix[-1] if prefix else None\n",
    "        n_prefix = prefix + (s,)\n",
    "        n_p_b, n_p_nb = next_beam[n_prefix]\n",
    "        if s != end_t:\n",
    "          n_p_nb = logsumexp(n_p_nb, p_b + p, p_nb + p)\n",
    "        else:\n",
    "          n_p_nb = logsumexp(n_p_nb, p_b + p)\n",
    "          \n",
    "        next_beam[n_prefix] = (n_p_b, n_p_nb)\n",
    "        if s == end_t:\n",
    "          n_p_b, n_p_nb = next_beam[prefix]\n",
    "          n_p_nb = logsumexp(n_p_nb, p_nb + p)\n",
    "          next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "    beam = sorted(next_beam.items(),\n",
    "            key=lambda x : logsumexp(*x[1]),\n",
    "            reverse=True)\n",
    "    beam = beam[:beam_size]\n",
    "\n",
    "  best = beam[0]\n",
    "  return best[0], -logsumexp(*best[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 17.042\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "time = 50\n",
    "output_dim = 20\n",
    "\n",
    "probs = out # np.random.rand(time, output_dim)\n",
    "probs = probs / np.sum(probs, axis=1, keepdims=True)\n",
    "\n",
    "label, score = decode(probs)\n",
    "\n",
    "print(\"Score {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ = ''\n",
    "for i in label:\n",
    "    out_+=labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I THINK IS IS GOINGNA BE VORY ALD IDEA IN THE BEAST IN INTELLETION ALDATI BUSINESSES IN THE YEARS TO COME I DONTWT'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.15384615384615"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_(out_,reference)/len(reference.split(' '))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/50 [00:10<08:42, 10.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUR PRODATIVITY AND OUR COMMITMENT TO OUR CLIENTS XXXUM TO MAKE SURE THAT WE NEED WHAT BE XXXUM PROMISED FOR THE DEADLINE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 2/50 [00:18<07:57,  9.94s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I MEALMY IS IMPORTANT XXXUM I I WOULD TELL M SURMURPHE THAT XXXUM THOUH WE WOULD PAY BU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|▌         | 3/50 [00:30<08:04, 10.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIM IS WILSON THIS IS RUN XXXUM Y MACHLY GON BECAUSE XXXUH IM STILL ANTHEIR FOR THE FLIGHTS AND DELAYE SINCE THERE IS BAD STORM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 4/50 [00:40<08:00, 10.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOI IU CANNOT I CANATTRAIN A MEETING IM SORRY I IRIGH I REALLY POTRIIES FOR WIR THIS SO MESSAGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|█         | 5/50 [00:51<07:52, 10.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " YOU KNOW ITS NOT WHAT I HAD PLANNED XH YOH I CAS XXH I JUST TEVER I KEEP YOU NOTD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|█▏        | 6/50 [00:54<06:06,  8.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " THEYARE ON THANK YOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|█▍        | 7/50 [01:05<06:28,  9.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MY PROFESSIONAL GOALS AND PLANES FOR THE NEXT DEN YEARS IS IM LOOKING FOR THE SUCCESS O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|█▌        | 8/50 [01:16<06:42,  9.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WETISH COMPANY AND IM LOKARDIM IM LOOKING FOR WAR FOR THE PROMOTION AND I SEE Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|█▊        | 9/50 [01:26<06:42,  9.81s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELF WHORKING IN THE REDISH COMPANIG SUCCESSFUL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 10/50 [01:36<06:35,  9.90s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HOPE MY CAREER WHILLE BE ECCESSFUL AF THER KEEN YEARS FRO NOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|██▏       | 11/50 [01:46<06:29, 10.00s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI CRINCS IM ICA AN UNSEN DAYGARE AT THE COMPANY HEADQUARTERS BECAUSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|██▍       | 12/50 [01:58<06:34, 10.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT WILL DESTER ME WHELE WARE KING AND IT TOL IT WILL RERTRYOU ARE WORKING AND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|██▌       | 13/50 [02:08<06:25, 10.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YH AND CHILDREN I IS VERY NICCE AND THEY WILL DIS HER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|██▊       | 14/50 [02:18<06:12, 10.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND IT WILL IRICATE MANY EMPLOYEES BECAUSE CHILDREN IS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|███       | 15/50 [02:29<06:02, 10.35s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TALKING LOD AND PLAING THEY WILL BE PLAY AT THE LOYT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|███▏      | 16/50 [02:39<05:53, 10.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND YEAH I AM AGAIN SO MASIDE TAKE CARE AT THE COMPANYS HEADQUARTERS BECAUSE IT CAES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|███▍      | 17/50 [02:51<05:51, 10.67s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT WILL DISHER BUS IT WILL DESTARVY THEMPLOEES IT WILL DISTERM THE NEAR OFFICES AND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|███▌      | 18/50 [03:00<05:32, 10.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN THE MAMIES WERE NOT IL LET ME FOR CUS ON THERE WERE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 19/50 [03:10<05:11, 10.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND AND YEAAH THEY SHOULD OVPV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 20/50 [03:20<05:02, 10.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIGGAR SO THEREIS AT TENITEL COMPANYS HEARD QUURTERS SO THAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|████▏     | 21/50 [03:25<04:11,  8.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO THA THAT YOUR FEL US THO GETN IMPLAYES MAKE A CUS ALITER WORK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|████▍     | 22/50 [03:36<04:22,  9.38s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE SIR WE HAVE TOS HAWISTICK NPLOMTATIONO OR BIDDING OUR EMPLOYES FROM ACCESSING SOLDIAN MEDIA WEBSITES INE NWIL AT WORK BECAUSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|████▌     | 23/50 [03:47<04:26,  9.87s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEY ARE HERE IN OUR COMPANY TO WORK FOCUS IN THEIR WORKD AND HAVE A CONTENTAATION ON THE WORK ONCE WE ALLOW THEM TO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|████▊     | 24/50 [03:58<04:26, 10.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS FUCIALL NEJIA WEBSITE WHILE ON WORK IT WILL DISTRACTTHEM FROM THEIR WORK AND WILL FOCUS AD AND WILL FOCUS AND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 25/50 [04:09<04:20, 10.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND THEY WILL HAVE A HAL FOCUS ON THEI WORK IN SOMETIMES IF WE ALLOWE THEM FROM DOING THAT MOST OF THE TIME BASE ON E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|█████▏    | 26/50 [04:20<04:13, 10.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COURD BASE AND SERVICS SOME OF OUR EMVLOYES SOME OF TE EMPLOYES CANNOT XXXUH CANNOT COMPLETE AND CANNOT FINISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|█████▍    | 27/50 [04:32<04:10, 10.91s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE JOB TAN ON TIME BECAUSE OF THE DESTRUCTION OF SOCIAL MEDIAREMSITES SO WHILE IT IS VERY AD I BELIEVE IT JIST VERY AVERY IMPORTANT THAT WE HAVE TO FORS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|█████▌    | 28/50 [04:43<04:04, 11.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR EMPLOYEES FROM ACCESSING SARCECIALL NEW JO EBSITE WHILLE WHILE ATWORK BECAUSE NOT NOT IN TWENTY FOR HOURS THAT THEY ARE WORKING THEY CAN HAVE TEI SOCIAL NEDI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|█████▊    | 29/50 [04:54<03:50, 10.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEBSITE XXH ACCESS DURING AFTER WORK OR BEFORE WORK AND THATS VERY AND IT AND IT THEY HAVE SO MUCH TIME OF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|██████    | 30/50 [05:05<03:42, 11.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT THEY ARE HERE BECAUSE OF THE WORK THAT WAS GIVEN TO THEM THEY WERE HIRED TO FOLLOW TO FOCUS ON THE JOB THAT WAS GIVEN TO THEM AND I GUESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|██████▏   | 31/50 [05:17<03:34, 11.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT IS BUT PROPER AND FAIRE TO AVERYONE IF WOU FORBID OUR EMPLOYES FROM ACCESSING SOCIAL MEED MEDIA REBSITE WHILE ATWARK THAT WOLL BE ALL A THANK YOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|██████▍   | 32/50 [05:27<03:15, 10.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEY CRIN TO REALIZE AR MORMING SIDE DIDNT I CODNT I TALL YOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|██████▌   | 33/50 [05:36<02:57, 10.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAN TO YOULIFE O IM ON YOUR SITE DIDING E YEU CINT IKE TELL YOU BUTIK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|██████▊   | 34/50 [05:46<02:42, 10.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I CAN FELD IT OUT FOR YOU YOU KNOW ITS NEVER GONNA TEA THAT SIMPLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 70%|███████   | 35/50 [05:56<02:33, 10.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O I CANT SPAR IT OUT FOR YOU SO T YOUL JUST REALISE FOR I CIN REALIFE AN THE PREX FOLIG ADHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|███████▏  | 36/50 [06:07<02:24, 10.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OEVEPEFINE ANOTHER I CEA LI MULNLI TUE REALI TO NEVER WONDER IT WIN DISTONE ON WECH OTHEN NOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|███████▍  | 37/50 [06:17<02:13, 10.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAK CINE TREALISE AM ON ON YOUR SHAL DIDNT I CODINT I TELL YOU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|███████▌  | 38/50 [06:27<02:00, 10.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW NOT A RUN O THE PLA STANDING NOUTATION BUT YOU POULD ANQUITE A SHOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|███████▊  | 39/50 [06:37<01:51, 10.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND MEET HOING NOW IT TIME TO GO PE IN SANLY CLOSING THAT WAS QUITE AS SHOW VELY IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|████████  | 40/50 [06:47<01:42, 10.24s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OE PLAINING BUT ITS OVERNOW GO ON AND TRATE AB BUT ITS OVERNOW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|████████▏ | 41/50 [06:58<01:32, 10.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO ON AN KAY ABOU WEN IS OVERNOW GO ON AND TAKE ABOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|████████▍ | 42/50 [07:03<01:09,  8.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUT ITS OE O GO ONE AND KATE AVAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|████████▌ | 43/50 [07:13<01:03,  9.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR NEVER XM BESSY XXXHI DO WORK AT AT HOME I DONAT LEAST THRE SETS EXERCISE  FIRST IS BUSH P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|████████▊ | 44/50 [07:24<00:58,  9.70s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECOND ONE IS  CARLOV AND THEN TE TARITHIS JUMKING JECK XUH IT WILL NOT CONSUME A LOT OF YOUR TIME SINCE THOSE ARE ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 90%|█████████ | 45/50 [07:34<00:49,  9.89s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR THOSE ARE ONLY IMPLEXERCASES THAT YOU CAN DO A TON WITHOUT HAVING ANY GYMQRIPMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|█████████▏| 46/50 [07:43<00:38,  9.53s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTHING THATS OLF TO XXXUH MEINTIN A HEALH TIU LAPSTEL I BEEN HORE ON THE TITES XXUH ERE SCHEDULE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|█████████▍| 47/50 [07:53<00:28,  9.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATS AH BUT SADTE AN IDEN IS GONNA BE A GREAT ARAY OPPORTUNI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|█████████▌| 48/50 [08:03<00:19,  9.90s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHEAP BECAUSE SHOL LEAR ANOTHER LANGUAE AS SI A ENGLISH THATS WILL OPEN EVERY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|█████████▊| 49/50 [08:14<00:10, 10.14s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR IN EVERY COMPANY OR COUNTRI WITH THE ENGLISH WITHEN INGLES LANGUIGE XXXUM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 50/50 [08:25<00:00, 10.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I THINK IS IS GOINGNA BE VORY ALD IDEA IN THE BEAST IN INTELLETION ALDATI BUSINESSES IN THE YEARS TO COME I DONTWT\n",
      "Test Summary \tAverage WER 47.585\tAverage CER 23.864\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# decoding = 'greedy'\n",
    "decoding = 'beam_w'\n",
    "# decoding = 'beam_c'\n",
    "prune = 0\n",
    "beam_width = 100\n",
    "alpha = 0\n",
    "beta = 0\n",
    "lm = lm_w\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\")\n",
    "model = load_model(device, \"/home/hemant/sopi_deep/models/deep/finetuen_sopi.pth\")\n",
    "spect_parser = SpectrogramParser(model.audio_conf, normalize=True)\n",
    "\n",
    "torch.cuda.set_device(int(0))\n",
    "with open(\"/home/hemant/sopi_deep/data/deepspeech/test/ata/test.csv\",\"r\") as f:\n",
    "    csv = f.readlines()\n",
    "\n",
    "total_cer, total_wer, num_tokens, num_chars = 0, 0, 0, 0\n",
    "lm = lm_w\n",
    "output = []\n",
    "for i in tqdm(csv):\n",
    "    audio_path, reference_path = i.split(\",\")\n",
    "\n",
    "    spect = spect_parser.parse_audio(audio_path).contiguous()\n",
    "    spect = spect.view(1, 1, spect.size(0), spect.size(1))\n",
    "    spect = spect.to(device)\n",
    "\n",
    "    input_sizes = torch.IntTensor([spect.size(3)]).int()\n",
    "    out, output_sizes = model(spect, input_sizes)\n",
    "    out = out.cpu().detach().numpy()[0]\n",
    "\n",
    "    label, score = decode(out)\n",
    "    transcript_ = ''\n",
    "    for i in label:\n",
    "        transcript_+=labels[i]\n",
    "    \n",
    "    with open(reference_path.replace(\"\\n\",\"\"),\"r\") as f:\n",
    "        reference = f.readline()\n",
    "        \n",
    "    print(transcript_)\n",
    "    wer_inst = wer_(transcript_,reference)\n",
    "    cer_inst = cer_(transcript_, reference)\n",
    "    total_wer += wer_inst\n",
    "    total_cer += cer_inst\n",
    "    num_tokens += len(reference.split(' '))\n",
    "    num_chars += len(reference.replace(' ', ''))\n",
    "        \n",
    "wer = (float(total_wer) / num_tokens)*100\n",
    "cer = (float(total_cer) / num_chars)*100\n",
    "print('Test Summary \\t'\n",
    "    'Average WER {wer:.3f}\\t'\n",
    "    'Average CER {cer:.3f}\\t'.format(wer=wer, cer=cer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
